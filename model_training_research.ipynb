{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_data(source_folder, destination_folder):\n",
    "    # Iterate through folders in the source directory\n",
    "    for company_folder in os.listdir(source_folder):\n",
    "        company_path = os.path.join(source_folder, company_folder)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(company_path):\n",
    "            # Check if the folder contains both index.html and selenium_full_screenshot.png\n",
    "            if 'index.html' in os.listdir(company_path) and 'selenium_full_screenshot.png' in os.listdir(company_path):\n",
    "                # Create a destination folder for the company\n",
    "                destination_company_folder = os.path.join(destination_folder, company_folder)\n",
    "\n",
    "                # Create the destination folder if it doesn't exist\n",
    "                if not os.path.exists(destination_company_folder):\n",
    "                    os.makedirs(destination_company_folder)\n",
    "\n",
    "                # Copy index.html and selenium_full_screenshot.png to the destination\n",
    "                shutil.copy(os.path.join(company_path, 'index.html'), destination_company_folder)\n",
    "                shutil.copy(os.path.join(company_path, 'selenium_full_screenshot.png'), destination_company_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    source_directory = \"test_data/output\"\n",
    "    destination_directory = \"prepared_data\"\n",
    "\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "\n",
    "    copy_data(source_directory, destination_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashok/projects/Gemini/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ashok/projects/Gemini/.venv/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "    loaded_dataset = Dataset.load_from_disk(output_dataset_path)\n",
    "    print(loaded_dataset)\n",
    "def extract_text_from_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "    return text\n",
    "\n",
    "def create_dataset(data_folder):\n",
    "    dataset_dict = {'html': [], 'text': [], 'image': []}\n",
    "\n",
    "    for company_folder in os.listdir(data_folder):\n",
    "        company_path = os.path.join(data_folder, company_folder)\n",
    "\n",
    "        if os.path.isdir(company_path):\n",
    "            html_path = os.path.join(company_path, 'index.html')\n",
    "            image_path = os.path.join(company_path, 'selenium_full_screenshot.png')\n",
    "\n",
    "            if os.path.exists(html_path) and os.path.exists(image_path):\n",
    "                with open(html_path, 'r', encoding='utf-8') as html_file:\n",
    "                    html_content = html_file.read()\n",
    "\n",
    "                    text = extract_text_from_html(html_content)\n",
    "\n",
    "                    # Open and convert the image to bytes\n",
    "                    with open(image_path, 'rb') as image_file:\n",
    "                        image_bytes = BytesIO(image_file.read())\n",
    "\n",
    "                    dataset_dict['html'].append(html_content)\n",
    "                    dataset_dict['text'].append(text)\n",
    "                    dataset_dict['image'].append(image_bytes)\n",
    "\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = \"prepared_data\"\n",
    "    output_dataset_path = \"html_text_image_dataset\"\n",
    "\n",
    "    dataset = create_dataset(data_folder)\n",
    "\n",
    "    # Save the dataset\n",
    "    dataset.save_to_disk(output_dataset_path)\n",
    "\n",
    "    # Example of loading the dataset\n",
    "    loaded_dataset = Dataset.load_from_disk(output_dataset_path)\n",
    "    print(loaded_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['html', 'text', 'image'],\n",
      "    num_rows: 4888\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashok/projects/Gemini/.venv/lib/python3.11/site-packages/datasets/table.py:1427: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "loaded_dataset = Dataset.load_from_disk('html_text_image_dataset')\n",
    "print(loaded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "first_image = loaded_dataset['image'][0]\n",
    "# Display the image\n",
    "plt.imshow(first_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load your datasets using the datasets library\\n\\n# Define your data collate function\\ndef collate_fn(batch):\\n    # Implement your collate function based on your data structure\\n    # Make sure it returns the necessary components (text, img, html, target)\\n    pass\\n\\n# Create DataLoader instances for training and validation\\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\\n#val_loader = DataLoader(dataset['test'], batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\\n\\n# Initialize model\\nmodel = Gemini(\\n    num_tokens=50432,\\n    max_seq_len=8192,\\n    dim=2560,\\n    depth=32,\\n    dim_head=128,\\n    heads=24,\\n    use_abs_pos_emb=False,\\n    alibi_pos_bias=True,\\n    alibi_num_heads=12,\\n    rotary_xpos=True,\\n    attn_flash=True,\\n    attn_kv_heads=2,\\n    qk_norm=True,\\n    attn_qk_norm=True,\\n    attn_qk_norm_dim_scale=True,\\n)\\n\\n\\n# Initialize PyTorch Lightning Trainer\\ntrainer = pl.Trainer(\\n    max_epochs=max_epochs,\\n    gpus=1 if torch.cuda.is_available() else 0,  # Use GPU if available\\n    progress_bar_refresh_rate=20,\\n)\\n\\n# Start training\\ntrainer.fit(model, train_loader)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import pytorch_lightning as pl\n",
    "from datasets import load_dataset  , load_from_disk\n",
    "# Import your existing Gemini model\n",
    "from gemini_torch import Gemini\n",
    "\n",
    "# Define your dataset name and path to data\n",
    "\n",
    "dataset_name = \"html_text_image_dataset\"\n",
    "\n",
    "# Define your batch size and maximum epochs\n",
    "batch_size = 16\n",
    "max_epochs = 10\n",
    "dataset = load_from_disk(dataset_name)\n",
    "'''\n",
    "# Load your datasets using the datasets library\n",
    "\n",
    "# Define your data collate function\n",
    "def collate_fn(batch):\n",
    "    # Implement your collate function based on your data structure\n",
    "    # Make sure it returns the necessary components (text, img, html, target)\n",
    "    pass\n",
    "\n",
    "# Create DataLoader instances for training and validation\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "#val_loader = DataLoader(dataset['test'], batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize model\n",
    "model = Gemini(\n",
    "    num_tokens=50432,\n",
    "    max_seq_len=8192,\n",
    "    dim=2560,\n",
    "    depth=32,\n",
    "    dim_head=128,\n",
    "    heads=24,\n",
    "    use_abs_pos_emb=False,\n",
    "    alibi_pos_bias=True,\n",
    "    alibi_num_heads=12,\n",
    "    rotary_xpos=True,\n",
    "    attn_flash=True,\n",
    "    attn_kv_heads=2,\n",
    "    qk_norm=True,\n",
    "    attn_qk_norm=True,\n",
    "    attn_qk_norm_dim_scale=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,  # Use GPU if available\n",
    "    progress_bar_refresh_rate=20,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model, train_loader)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html', 'text', 'image'],\n",
       "    num_rows: 4888\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With nearly 200 program offerings, 250-plus unique student organizations, daily campus events, community outreach, innovative research, performing arts and Division I athletics, there's a place for everyone at SDSU.Schedule a visitApply online Schedule a visitApply online Student Resources: Academic Calendar View the SDSU Academic Calendar for important Fall, Spring and Summer dates. Visit Campus Come meet the people that will help shape your future and define your college experience! Awards and Rankings Numerous entities rank SDSU’s colleges and academic programs among the nation’s best. Student Life Maximize your Jackrabbit experience by engaging with new people, joining a club, attending events and getting involved in the community. There is so much that our SDSU community has to offer. The Wintrode Student Success and Opportunity Center The Opportunity Center embraces SDSU’s land-grant mission by supporting educational access for all students. American Indian Opportunities SDSU seeks to create a welcoming and supportive campus environment for American Indian students through a variety of academic programs, scholarships, student services and initiatives.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['image'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
